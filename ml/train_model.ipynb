{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement Modèle ML avec MLflow\n",
    "\n",
    "**Données multi-sources** :\n",
    "- Source 1: API RTE (consommation)\n",
    "- Source 2: Fichier CSV (jours fériés)\n",
    "- Source 3: Web scrapping (prix spot)\n",
    "\n",
    "**Tracking** : MLflow pour versioning et comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Style plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration MLflow\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "mlflow.set_experiment(\"rte_consommation_3sources\")\n",
    "\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())\n",
    "print(\"Experiment:\", mlflow.get_experiment_by_name(\"rte_consommation_3sources\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement Données Enrichies (3 sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger données fusionnées\n",
    "data_path = \"../data/conso_enrichi_3sources.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "print(f\"Données chargées: {len(df)} enregistrements\")\n",
    "print(f\"Période: {df['datetime'].min()} -> {df['datetime'].max()}\")\n",
    "print(f\"\\nColonnes: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aperçu des données\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corrélation\n",
    "corr_cols = ['mw_conso', 'prix_spot_eur_mwh', 'heure', 'jour_semaine', 'est_ferie', 'est_vacances', 'est_weekend']\n",
    "correlation = df[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, fmt='.3f')\n",
    "plt.title('Matrice de corrélation')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrélations avec consommation:\")\n",
    "print(correlation['mw_conso'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Préparation Features et Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features multi-sources\n",
    "features = [\n",
    "    'heure',                  # Feature temporelle\n",
    "    'jour_semaine',           # Feature temporelle\n",
    "    'mois',                   # Feature temporelle\n",
    "    'jour_mois',              # Feature temporelle\n",
    "    'est_weekend',            # Feature temporelle\n",
    "    'prix_spot_eur_mwh',      # Source 3: Web scrapping\n",
    "    'est_ferie',              # Source 2: Fichier texte\n",
    "    'est_vacances'            # Source 2: Fichier texte\n",
    "]\n",
    "\n",
    "target = 'mw_conso'  # Source 1: API RTE\n",
    "\n",
    "print(f\"Features utilisées ({len(features)}):\")\n",
    "for i, feat in enumerate(features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "print(f\"\\nTarget: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer X et y\n",
    "df_clean = df.dropna(subset=[target] + features)\n",
    "\n",
    "X = df_clean[features]\n",
    "y = df_clean[target]\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nLignes supprimées (NaN): {len(df) - len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"Split ratio: {len(X_train)/len(X)*100:.1f}% / {len(X_test)/len(X)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entraînement avec MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres\n",
    "params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 15,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "print(\"Hyperparamètres:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Démarrer run MLflow\n",
    "with mlflow.start_run(run_name=f\"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"   MLflow Run Started\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Log paramètres\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(\"train_size\", len(X_train))\n",
    "    mlflow.log_param(\"test_size\", len(X_test))\n",
    "    mlflow.log_param(\"nb_features\", len(features))\n",
    "    mlflow.log_param(\"features\", features)\n",
    "    \n",
    "    # Tags\n",
    "    mlflow.set_tag(\"model_type\", \"RandomForestRegressor\")\n",
    "    mlflow.set_tag(\"data_sources\", \"API_RTE + Fichier_CSV + Web_Scrapping\")\n",
    "    mlflow.set_tag(\"nb_sources\", \"3\")\n",
    "    mlflow.set_tag(\"training_date\", datetime.now().isoformat())\n",
    "    \n",
    "    # Entraînement\n",
    "    print(\"\\nEntraînement du modèle...\")\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Entraînement terminé!\")\n",
    "    \n",
    "    # Cross-validation\n",
    "    print(\"\\nCross-validation (5-fold)...\")\n",
    "    cv_scores = cross_val_score(\n",
    "        model, X_train, y_train,\n",
    "        cv=5, scoring='neg_mean_absolute_error'\n",
    "    )\n",
    "    cv_mae = -cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    mlflow.log_metric(\"cv_mae\", cv_mae)\n",
    "    mlflow.log_metric(\"cv_std\", cv_std)\n",
    "    \n",
    "    print(f\"CV MAE: {cv_mae:.2f} ± {cv_std:.2f} MW\")\n",
    "    \n",
    "    # Prédictions\n",
    "    print(\"\\nPrédictions sur test set...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Métriques\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "    # Log métriques\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "    mlflow.log_metric(\"mape_percent\", mape)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"   Métriques\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"MAE:  {mae:.2f} MW\")\n",
    "    print(f\"RMSE: {rmse:.2f} MW\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nImportance des features:\")\n",
    "    print(feature_importance.to_string(index=False))\n",
    "    \n",
    "    # Log importance\n",
    "    for idx, row in feature_importance.iterrows():\n",
    "        mlflow.log_metric(f\"importance_{row['feature']}\", row['importance'])\n",
    "    \n",
    "    # Sauvegarde modèle\n",
    "    model_path = Path(\"models/rte_conso_model_3sources.pkl\")\n",
    "    model_path.parent.mkdir(exist_ok=True)\n",
    "    joblib.dump(model, model_path)\n",
    "    \n",
    "    # Log modèle MLflow\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,\n",
    "        \"model\",\n",
    "        registered_model_name=\"RTEConsommation3Sources\"\n",
    "    )\n",
    "    \n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    print(f\"\\nMLflow Run ID: {run_id}\")\n",
    "    print(f\"Modèle sauvegardé: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Importance des Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions vs Réel\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test, y_pred, alpha=0.5)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Consommation Réelle (MW)')\n",
    "axes[0].set_ylabel('Consommation Prédite (MW)')\n",
    "axes[0].set_title(f'Prédictions vs Réel (R² = {r2:.3f})')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Résidus\n",
    "residuals = y_test - y_pred\n",
    "axes[1].scatter(y_pred, residuals, alpha=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Consommation Prédite (MW)')\n",
    "axes[1].set_ylabel('Résidus (MW)')\n",
    "axes[1].set_title('Analyse des Résidus')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des erreurs\n",
    "errors = np.abs(y_test - y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(errors, bins=30, edgecolor='black')\n",
    "plt.xlabel('Erreur Absolue (MW)')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.title('Distribution des Erreurs Absolues')\n",
    "plt.axvline(mae, color='r', linestyle='--', label=f'MAE = {mae:.2f} MW')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(errors)\n",
    "plt.ylabel('Erreur Absolue (MW)')\n",
    "plt.title('Boxplot des Erreurs')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Erreur médiane: {np.median(errors):.2f} MW\")\n",
    "print(f\"Erreur max: {np.max(errors):.2f} MW\")\n",
    "print(f\"95% des erreurs < {np.percentile(errors, 95):.2f} MW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test sur quelques exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendre 10 exemples aléatoires du test set\n",
    "sample_idx = np.random.choice(len(X_test), 10, replace=False)\n",
    "\n",
    "X_sample = X_test.iloc[sample_idx]\n",
    "y_sample_true = y_test.iloc[sample_idx]\n",
    "y_sample_pred = model.predict(X_sample)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Réel (MW)': y_sample_true.values,\n",
    "    'Prédit (MW)': y_sample_pred,\n",
    "    'Erreur (MW)': np.abs(y_sample_true.values - y_sample_pred),\n",
    "    'Erreur (%)': np.abs((y_sample_true.values - y_sample_pred) / y_sample_true.values * 100)\n",
    "})\n",
    "\n",
    "print(\"Exemples de prédictions:\")\n",
    "print(comparison.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Résumé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"   RÉSUMÉ ENTRAÎNEMENT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDonnées:\")\n",
    "print(f\"  - Sources: 3 (API + Fichier + Scrapping)\")\n",
    "print(f\"  - Total samples: {len(X)}\")\n",
    "print(f\"  - Features: {len(features)}\")\n",
    "print(f\"\\nModèle: RandomForestRegressor\")\n",
    "print(f\"  - n_estimators: {params['n_estimators']}\")\n",
    "print(f\"  - max_depth: {params['max_depth']}\")\n",
    "print(f\"\\nPerformances:\")\n",
    "print(f\"  - MAE: {mae:.2f} MW\")\n",
    "print(f\"  - RMSE: {rmse:.2f} MW\")\n",
    "print(f\"  - R²: {r2:.4f}\")\n",
    "print(f\"  - MAPE: {mape:.2f}%\")\n",
    "print(f\"\\nTop 3 features importantes:\")\n",
    "for i, row in feature_importance.head(3).iterrows():\n",
    "    print(f\"  {row['feature']}: {row['importance']:.4f}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Pour visualiser dans MLflow UI:\")\n",
    "print(\"  mlflow ui\")\n",
    "print(\"  puis ouvrir: http://localhost:5000\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
